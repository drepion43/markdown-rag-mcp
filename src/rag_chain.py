import os
import asyncio
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from langchain.schema import Document
from langchain.prompts import PromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import Runnable
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RAGChain:
    def __init__(self, llm: object, embeddings: Optional[object] = None):
        self.llm = llm
        # embeddings ì´ˆê¸°í™” ì‹œ API í‚¤ í™•ì¸
        OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
        if not OPENAI_API_KEY:
            logger.error("OPENAI_API_KEY is not set in RAGChain")
            raise ValueError("OPENAI_API_KEY is not set")
        self.embeddings = embeddings or OpenAIEmbeddings(
            model="text-embedding-ada-002",
            openai_api_key=OPENAI_API_KEY,
            timeout=30
        )

    async def create_retriever(self, markdown_text: str):
        """Markdown í…ìŠ¤íŠ¸ â†’ Retriever ìƒì„±"""
        try:
            logger.info("Creating retriever from markdown text")
            doc = Document(page_content=markdown_text)
            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
            split_docs = splitter.split_documents([doc])
            vector = FAISS.from_documents(split_docs, self.embeddings)
            return vector.as_retriever()
        except Exception as e:
            logger.error(f"Failed to create retriever: {str(e)}")
            raise

    def format_docs(self, docs: List[Document]) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³‘í•©"""
        return "\n".join([doc.page_content for doc in docs])

    async def invoke(self, inputs: Dict[str, Any]) -> str:
        try:
            async with asyncio.timeout(45):  # 45ì´ˆ íƒ€ì„ì•„ì›ƒ
                question: str = inputs.get("question", "")
                context_docs: List[Document] = inputs.get("context", [])
                history: List[str] = inputs.get("chat_history", [])

                logger.info(f"Invoking RAG chain with question: {question}")
                context_text = self.format_docs(context_docs) if isinstance(context_docs, list) else context_docs
                history_text = "\n".join(history)

                prompt = PromptTemplate.from_template(
                    """
                    ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AIì…ë‹ˆë‹¤.

                    ğŸ”¹ ê³¼ê±° ëŒ€í™” ë‚´ìš© (ì°¸ê³ ìš©):
                    {chat_history}
                    (ê³¼ê±° ëŒ€í™”ëŠ” ì‚¬ìš©ìê°€ ì´ì „ì— ë¬¼ì–´ë³¸ ì§ˆë¬¸ê³¼ ê·¸ì— ëŒ€í•œ ë‹µë³€ë“¤ì…ë‹ˆë‹¤. ì´ ëŒ€í™”ëŠ” ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•˜ë©°, ì‚¬ìš©ìê°€ ê³„ì†í•´ì„œ ì§„í–‰í•˜ê³ ì í•˜ëŠ” ëŒ€í™”ì˜ íë¦„ì„ ì¶”ì í•´ì•¼ í•©ë‹ˆë‹¤.)

                    ğŸ”¹ ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© (ë°˜ë“œì‹œ ì°¸ê³ ):
                    {context}
                    (ê²€ìƒ‰ëœ ë¬¸ì„œëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì œê³µí•  ë•Œ ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ì…ë‹ˆë‹¤. ë¬¸ì„œì—ì„œ ì œê³µëœ ë‚´ìš©ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.)

                    ğŸ’¬ ì‚¬ìš©ì ì§ˆë¬¸:
                    {question}
                    (ì´ ì§ˆë¬¸ì€ ì‚¬ìš©ìê°€ í˜„ì¬ ì›í•˜ëŠ” ì •ë³´ì…ë‹ˆë‹¤. ë‹µë³€ì€ ì´ ì§ˆë¬¸ì„ ì§ì ‘ì ìœ¼ë¡œ ë‹¤ë¤„ì•¼ í•©ë‹ˆë‹¤.)

                    ğŸ“Œ ì§€ì¹¨:
                    - ê³¼ê±° ëŒ€í™” ë‚´ìš©ì€ í˜„ì¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë§¥ë½ì„ ì œê³µí•©ë‹ˆë‹¤. ëŒ€í™”ì˜ íë¦„ì„ ë†“ì¹˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
                    - ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
                    - ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”.
                    - ê°„ê²°í•˜ê³  ì „ë¬¸ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.

                    ğŸ§  ë‹µë³€:
                    """
                )

                chain: Runnable = prompt | self.llm | StrOutputParser()
                response = await chain.ainvoke({
                    "chat_history": history_text,
                    "context": context_text,
                    "question": question
                })
                return response
        except asyncio.TimeoutError:
            logger.error("RAG chain invocation timed out after 45 seconds")
            return "Error: RAG processing timed out"
        except Exception as e:
            logger.error(f"RAG chain invocation failed: {str(e)}")
            return f"Error: {str(e)}"